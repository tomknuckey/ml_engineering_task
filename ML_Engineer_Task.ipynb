{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Data generation function - this is not part of the task, and is only to simulate pulling from a SQL database\n",
    "# Don't worry about changing this - it's just to make the notebook a little easier!\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def collect_from_database(query: str) -> pd.DataFrame:\n",
    "    print(f\"Executing: {query}\")\n",
    "    n_rows = 10_000\n",
    "    n_features = 16\n",
    "    features, labels = make_classification(\n",
    "        n_samples = n_rows,\n",
    "        n_features = 16,\n",
    "        n_informative = 7,\n",
    "        n_redundant = 4,\n",
    "        n_repeated = 3,\n",
    "        n_classes = 2,\n",
    "        class_sep = 1.2,\n",
    "        flip_y = 0.035, # Randomly invert y for added noise\n",
    "        weights = [0.85,0.15],\n",
    "        random_state = 1889,\n",
    "    )\n",
    "    df = pd.DataFrame(features, columns=[f'numeric_{i+1}' for i in range(n_features)])\n",
    "    df.insert(value=labels, loc=0, column='claim_status')\n",
    "    df = df.rename(columns={\n",
    "        'numeric_1': 'age',\n",
    "        'numeric_2': 'height_cm',\n",
    "        'numeric_3': 'weight_kg',\n",
    "        'numeric_4': 'income',\n",
    "        'numeric_5': 'financial_hist_1',\n",
    "        'numeric_6': 'financial_hist_2',\n",
    "        'numeric_7': 'financial_hist_3',\n",
    "        'numeric_8': 'financial_hist_4',\n",
    "        'numeric_9': 'credit_score_1',\n",
    "        'numeric_10': 'credit_score_2',\n",
    "        'numeric_11': 'credit_score_3',\n",
    "        'numeric_12': 'insurance_hist_1',\n",
    "        'numeric_13': 'insurance_hist_2',\n",
    "        'numeric_14': 'insurance_hist_3',\n",
    "        'numeric_15': 'insurance_hist_4',\n",
    "        'numeric_16': 'insurance_hist_5',\n",
    "    })\n",
    "    df['age'] = MinMaxScaler(feature_range=(18, 95)).fit_transform(df['age'].values[:, None])\n",
    "    df['age'] = df['age'].astype('int')\n",
    "    df['height_cm'] = MinMaxScaler(feature_range=(140, 210)).fit_transform(df['height_cm'].values[:, None])\n",
    "    df['height_cm'] = df['height_cm'].astype('int')\n",
    "    df['weight_kg'] = MinMaxScaler(feature_range=(45, 125)).fit_transform(df['weight_kg'].values[:, None])\n",
    "    df['weight_kg'] = df['weight_kg'].astype('int')\n",
    "    df['income'] = MinMaxScaler(feature_range=(0, 250_000)).fit_transform(df['income'].values[:, None])\n",
    "    df['income'] = df['income'].astype('int')\n",
    "    df['credit_score_1'] = MinMaxScaler(feature_range=(0, 999)).fit_transform(df['credit_score_1'].values[:, None])\n",
    "    df['credit_score_1'] = df['credit_score_1'].astype('int')\n",
    "    df['credit_score_2'] = MinMaxScaler(feature_range=(0, 700)).fit_transform(df['credit_score_2'].values[:, None])\n",
    "    df['credit_score_2'] = df['credit_score_2'].astype('int')\n",
    "    df['credit_score_3'] = MinMaxScaler(feature_range=(0, 710)).fit_transform(df['credit_score_3'].values[:, None])\n",
    "    df['credit_score_3'] = df['credit_score_3'].astype('int')\n",
    "    df['bmi'] = (df['weight_kg']/((df['height_cm']/100)**2)).astype('int')\n",
    "    df['gender'] = np.where(\n",
    "        df['claim_status'] == 0,\n",
    "        np.random.choice([1, 0], size=(n_rows), p=[0.46, 0.54]),\n",
    "        np.random.choice([1, 0], size=(n_rows), p=[0.52, 0.48])\n",
    "        )\n",
    "    df['marital_status'] = np.random.choice(['A', 'B', 'C', 'D', 'E', 'F'], size=(n_rows), p=[0.2, 0.15, 0.1, 0.25, 0.15, 0.15])\n",
    "    df['occupation'] = np.random.choice(['A', 'B', 'C', 'D', 'E', 'F', 'G'], size=(n_rows))\n",
    "    df['location'] = np.random.choice(list(string.ascii_uppercase), size=(n_rows))\n",
    "    df['prev_claim_rejected'] = np.where(\n",
    "        df['claim_status'] == 0,\n",
    "        np.random.choice([1, 0], size=(n_rows), p=[0.08, 0.92]),\n",
    "        np.random.choice([1, 0], size=(n_rows), p=[0.16, 0.84])\n",
    "        )\n",
    "    df['known_health_conditions'] = np.random.choice([1, 0], size=(n_rows), p=[0.06, 0.94])\n",
    "    df['uk_residence'] = np.random.choice([1, 0], size=(n_rows), p=[0.76, 0.24])\n",
    "    df['family_history_1'] = np.random.choice([1, 0], size=(n_rows), p=[0.22, 0.78])\n",
    "    df['family_history_2'] = np.random.choice([1, 0], size=(n_rows), p=[0.25, 0.75])\n",
    "    df['family_history_3'] = np.random.choice([1, None, 0], size=(n_rows), p=[0.12, 0.81, 0.07])\n",
    "    df['family_history_4'] = np.random.choice([1, 0], size=(n_rows), p=[0.27, 0.73])\n",
    "    df['family_history_5'] = np.random.choice([1, 0], size=(n_rows), p=[0.31, 0.69])\n",
    "    df['product_var_1'] = np.random.choice([1, 0], size=(n_rows), p=[0.38, 0.62])\n",
    "    df['product_var_2'] = np.random.choice([1, 0], size=(n_rows), p=[0.55, 0.45])\n",
    "    df['product_var_3'] = np.random.choice(['A', 'B', 'C', 'D'], size=(n_rows), p=[0.23, 0.28, 0.31, 0.18])\n",
    "    df['product_var_4'] = np.random.choice([1, 0], size=(n_rows), p=[0.76, 0.24])\n",
    "    df['health_status'] = np.random.randint(1, 5, size=(n_rows))\n",
    "    df['driving_record'] = np.random.randint(1, 5, size=(n_rows))\n",
    "    df['previous_claim_rate'] = np.where(\n",
    "        df['claim_status'] == 0,\n",
    "        np.random.choice([1, 2, 3, 4, 5], size=(n_rows), p=[0.48, 0.29, 0.12, 0.08, 0.03]),\n",
    "        np.random.choice([1, 2, 3, 4, 5], size=(n_rows), p=[0.12, 0.28, 0.34, 0.19, 0.07]),\n",
    "    )\n",
    "    df['education_level'] = np.random.randint(0, 7, size=(n_rows))\n",
    "    df['income level'] = pd.cut(df['income'], bins=5, labels=False, include_lowest=True)\n",
    "    df['n_dependents'] = np.random.choice(\n",
    "        [1, 2, 3, 4, 5], size=(n_rows), p=[0.23, 0.32, 0.27, 0.11, 0.07]\n",
    "    )\n",
    "    df['employment_type'] = np.random.choice(\n",
    "        [1, None, 0], size=(n_rows), p=[0.16, 0.7, 0.14]\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Pre-selection Task:** Alex's Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pan\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.datasets import *\n",
    "from sklearn.metrics import cohen_kappa_score, accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, roc_auc_score, confusion_matrix, log_loss, roc_curve\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import string\n",
    "import shap\n",
    "\n",
    "#Seed\n",
    "np.random.seed(1889)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "account_name = \"rg_data_sci\"\n",
    "client_id = \"a1b2c3d4\"\n",
    "# client_secret = \"b1c2d3e4\" #Delete before commiting to ADO!!!\n",
    "subscription_id = \"8a7b6c5d\"\n",
    "tenant_id = \"6f5g4h3i\"\n",
    "datalake_name = \"rg_data_lake\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_from_database = collect_from_database(\n",
    "    \"SELECT * FROM CLAIMS.DS_DATASET\"\n",
    ")\n",
    "dataset_from_database.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check distribution of labels\n",
    "dataset_from_database['claim_status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optionally save CSV locally\n",
    "\n",
    "# dataset_from_database.to_csv(\"dataset_from_database.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = dataset_from_database.isnull().sum()\n",
    "percent = (dataset_from_database.isnull().sum() / dataset_from_database.isnull().count()*100)\n",
    "missing_df = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "types = []\n",
    "for col in dataset_from_database.columns:\n",
    "    dtype = str(dataset_from_database[col].dtype)\n",
    "    types.append(dtype)\n",
    "missing_df['Types'] = types\n",
    "dataset_from_database_no_missing_values = pd.DataFrame()\n",
    "dataset_from_database_no_missing_values = dataset_from_database.drop(columns=['family_history_3', 'employment_type'])\n",
    "dataset_from_database.drop(columns=['family_history_3', 'employment_type'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in dataset_from_database.columns:\n",
    "    print(f\"Column: {i}, dtype: {dataset_from_database[i].dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_numerical = ['gender', 'marital_status', 'occupation', 'location', 'prev_claim_rejected', 'known_health_conditions', 'uk_residence', 'family_history_1', 'family_history_2', 'family_history_4', 'family_history_5', 'product_var_1', 'product_var_2', 'product_var_3', 'health_status', 'driving_record', 'previous_claim_rate', 'education_level', 'income level', 'n_dependents']\n",
    "\n",
    "for column in non_numerical:\n",
    "    dataset_from_database[column] = dataset_from_database[column].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(dataset_from_database, hue='claim_status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = dataset_from_database[\n",
    "    dataset_from_database.columns.drop([\"product_var_3\", \"marital_status\", \"occupation\", \"location\"])\n",
    "].corr()\n",
    "diag_mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "# Create axes and colourmap\n",
    "fig, ax = plt.subplots(figsize=(11, 9))\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "\n",
    "sns.heatmap(\n",
    "    corr,\n",
    "    mask=diag_mask,\n",
    "    cmap=cmap,\n",
    "    vmax=0.3,\n",
    "    center=0,\n",
    "    square=True,\n",
    "    linewidths=0.5,\n",
    "    cbar_kws={\"shrink\": 0.5},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in ['age', 'height_cm', 'weight_kg', 'income', 'financial_hist_1', 'financial_hist_2', 'financial_hist_3', 'financial_hist_4','credit_score_1', 'credit_score_2', 'credit_score_3', 'insurance_hist_1', 'insurance_hist_2', 'insurance_hist_3', 'insurance_hist_4']:\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(6,4))\n",
    "    sns.boxplot(data=dataset_from_database, y = column, orient='v', ax=ax[0])\n",
    "    sns.histplot(dataset_from_database, x = column, kde=True, ax=ax[1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_plots = dataset_from_database.columns.drop(['claim_status', 'financial_hist_1', 'financial_hist_2', 'financial_hist_3', 'financial_hist_4',  'insurance_hist_1', 'insurance_hist_2', 'insurance_hist_3', 'insurance_hist_4', 'insurance_hist_5', 'income'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the Dataframe into labels and features\n",
    "X, y = dataset_from_database.drop('claim_status', axis=1), dataset_from_database[['claim_status']]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1889)\n",
    "\n",
    "# Build the evaluation set & metric list\n",
    "eval_set = [(X_train, y_train)]\n",
    "eval_metrics = ['auc', 'rmse', 'logloss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    eval_metric=eval_metrics,\n",
    "    enable_categorical=True\n",
    ")\n",
    "\n",
    "model.fit(X_test, y_test, eval_set=eval_set, verbose=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import cohen_kappa_score, accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, roc_auc_score, confusion_matrix, log_loss, roc_curve\n",
    "\n",
    "train_class_preds = model.predict(X_train)\n",
    "test_class_preds = model.predict(X_test)\n",
    "train_prob_preds = model.predict_proba(X_train)[:, 1]\n",
    "test_prob_preds = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "y = np.array(y_train)\n",
    "y = y.astype(int)\n",
    "yhat = np.array(train_class_preds)\n",
    "yhat = np.clip(np.round(yhat), np.min(y), np.max(y)).astype(int)\n",
    "training_data_kappa_score = round(cohen_kappa_score(yhat, y, weights='quadratic'), 2)\n",
    "print(\n",
    "f\"The Cohen Kappa score on the training data is: {training_data_kappa_score}\"\n",
    ")\n",
    "\n",
    "y = np.array(y_test)\n",
    "y = y.astype(int)\n",
    "yhat = np.array(test_class_preds)\n",
    "yhat = np.clip(np.round(yhat), np.min(y), np.max(y)).astype(int)\n",
    "test_data_kappa_score = round(cohen_kappa_score(yhat, y, weights='quadratic'), 2)\n",
    "print(\n",
    "f\"The Cohen Kappa score on the test data is: {test_data_kappa_score}\"\n",
    ")\n",
    "\n",
    "print()\n",
    "print(\"The accuracy on train dataset is: \", accuracy_score(y_train, train_class_preds))\n",
    "print(\"The accuracy on test dataset is: \", accuracy_score(y_test, test_class_preds))\n",
    "\n",
    "print()\n",
    "print(\"Train confusion matrix: \", confusion_matrix(y_train, train_class_preds))\n",
    "\n",
    "print()\n",
    "print(\"Test confusion matrix: \", confusion_matrix(y_test, test_class_preds))\n",
    "\n",
    "print()\n",
    "print(\"ROC on train data: \", roc_auc_score(y_train, train_prob_preds))\n",
    "print(\"ROC on test data: \", roc_auc_score(y_test, test_prob_preds))\n",
    "\n",
    "print()\n",
    "fpr, tpr, _ = roc_curve(y_test, test_prob_preds)\n",
    "random_fpr, random_tpr, _ = roc_curve(y_test, [0 for _ in range(len(y_test))])\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "plt.plot(fpr, tpr, marker='.', label='XGBoost')\n",
    "plt.plot(random_fpr, random_tpr, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title(\"Receiver Operating Curve\")\n",
    "print(\"Train log loss: \", log_loss(y_train, train_prob_preds))\n",
    "print(\"Test log loss: \", log_loss(y_test, test_prob_preds))\n",
    "\n",
    "print()\n",
    "print(\"F1 score is: \", f1_score(y_test, test_class_preds))\n",
    "print(\"Precision is: \", precision_score(y_test, test_class_preds))\n",
    "print(\"Recall is: \", recall_score(y_test, test_class_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC Curve suggests amazing performance - espeically for an initial model! easier than expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1, ax1 = plt.subplots(figsize=(12, 6))\n",
    "xgb.plot_importance(model, ax=ax1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2, ax2 = plt.subplots(figsize=(16,16))\n",
    "xgb.plot_tree(model, rankdir='LR', ax=ax2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CV Model Training\n",
    "- Cross Vaildation tests to see if I can improve the model performance - not sure if it's useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_gridSearch = RandomizedSearchCV(\n",
    "    estimator=xgb.XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    eval_metric=eval_metrics,\n",
    "    early_stopping_rounds=15,\n",
    "    enable_categorical=True,\n",
    "    ),\n",
    "\n",
    "    param_distributions={\n",
    "    'n_estimators': stats.randint(50, 500),\n",
    "    'learning_rate': stats.uniform(0.01, 0.75),\n",
    "    'subsample': stats.uniform(0.25, 0.75),\n",
    "    'max_depth': stats.randint(1, 8),\n",
    "    'colsample_bytree': stats.uniform(0.1, 0.75),\n",
    "    'min_child_weight': [1, 3, 5, 7, 9],\n",
    "    },\n",
    "\n",
    "    cv=5,\n",
    "    n_iter=100,\n",
    "    verbose=False,\n",
    "    scoring='roc_auc',\n",
    ")\n",
    "\n",
    "parameter_gridSearch.fit(X_train, y_train, eval_set=eval_set, verbose=False)\n",
    "\n",
    "print(\"Best parameters are: \", parameter_gridSearch.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = xgb.XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    eval_metric=eval_metrics,\n",
    "    early_stopping_rounds=15,\n",
    "    enable_categorical=True,\n",
    "    **parameter_gridSearch.best_params_ #Not sure what this does, from StackOverflow\n",
    "    )\n",
    "\n",
    "model3.fit(X_train, y_train, eval_set=eval_set, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import cohen_kappa_score, accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, roc_auc_score, confusion_matrix, log_loss, roc_curve\n",
    "\n",
    "train_class_preds2 = model3.predict(X_train)\n",
    "test_class_preds2 = model3.predict(X_test)\n",
    "train_prob_preds2 = model3.predict_proba(X_train)[:, 1]\n",
    "test_prob_preds2 = model3.predict_proba(X_test)[:, 1]\n",
    "\n",
    "y = np.array(y_train)\n",
    "y = y.astype(int)\n",
    "yhat = np.array(train_class_preds2)\n",
    "yhat = np.clip(np.round(yhat), np.min(y), np.max(y)).astype(int)\n",
    "kappa2 = round(cohen_kappa_score(yhat, y, weights='quadratic'), 2)\n",
    "print(\n",
    "f\"The Cohen Kappa score on the training data is: {kappa2}\"\n",
    ")\n",
    "\n",
    "y = np.array(y_test)\n",
    "y = y.astype(int)\n",
    "yhat = np.array(test_class_preds)\n",
    "yhat = np.clip(np.round(yhat), np.min(y), np.max(y)).astype(int)\n",
    "kappa2 = round(cohen_kappa_score(yhat, y, weights='quadratic'), 2)\n",
    "print(\n",
    "f\"The Cohen Kappa score on the test data is: {kappa2}\"\n",
    ")\n",
    "\n",
    "print()\n",
    "print(\"The accuracy on train dataset is: \", accuracy_score(y_train, train_class_preds2))\n",
    "print(\"The accuracy on test dataset is: \", accuracy_score(y_test, test_class_preds2))\n",
    "\n",
    "print()\n",
    "print(\"Train confusion matrix: \", confusion_matrix(y_train, train_class_preds2))\n",
    "\n",
    "print()\n",
    "print(\"Test confusion matrix: \", confusion_matrix(y_test, test_class_preds2))\n",
    "\n",
    "print()\n",
    "print(\"ROC on train data: \", roc_auc_score(y_train, train_prob_preds2))\n",
    "print(\"ROC on test data: \", roc_auc_score(y_test, test_prob_preds2))\n",
    "\n",
    "print()\n",
    "fpr, tpr, _ = roc_curve(y_test, test_prob_preds2)\n",
    "random_fpr, random_tpr, _ = roc_curve(y_test, [0 for _ in range(len(y_test))])\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "plt.plot(fpr, tpr, marker='.', label='XGBoost')\n",
    "plt.plot(random_fpr, random_tpr, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title(\"Receiver Operating Curve\")\n",
    "print(\"Train log loss: \", log_loss(y_train, train_prob_preds2))\n",
    "print(\"Test log loss: \", log_loss(y_test, test_prob_preds2))\n",
    "\n",
    "print()\n",
    "print(\"F1 score is: \", f1_score(y_test, test_class_preds2))\n",
    "print(\"Precision is: \", precision_score(y_test, test_class_preds2))\n",
    "print(\"Recall is: \", recall_score(y_test, test_class_preds2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "less performance in the ROC curve??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Shap Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()\n",
    "\n",
    "shap_values = model3.get_booster().predict(\n",
    "    xgb.DMatrix(X_train, y_train, enable_categorical=True), pred_contribs=True\n",
    ")\n",
    "\n",
    "native_model = model3.get_booster()\n",
    "shap_values = native_model.predict(\n",
    "    xgb.DMatrix(X_train, y_train, enable_categorical=True), pred_contribs=True\n",
    ")\n",
    "\n",
    "shap.summary_plot(shap_values[:, :-1], X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "model3.save_model(\"xgboost_model_optimised_with_cross_validation.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "standard",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
